services:
  kafka0:
    image: confluentinc/cp-kafka:7.6.1
    restart: on-failure:5
    hostname: kafka0
    container_name: kafka0
    ports:
      - "9092:9092"
      - "9997:9997"
    environment:
      CLUSTER_ID: gTCA24KBTQGmpnFv6eLPzA
      KAFKA_NODE_ID: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka0:29093,2@kafka1:29093,3@kafka2:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka0:29092,CONTROLLER://kafka0:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka0:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9997
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      KAFKA_COMPRESSION_TYPE: producer
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    volumes:
      - ./volumes/kafka/kafka0:/tmp/kraft-combined-logs
    extends:
      file: common-config.yml
      service: network-deploy-service

  kafka1:
    image: confluentinc/cp-kafka:7.6.1
    restart: on-failure:5
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9093:9093"
      - "9998:9998"
    environment:
      CLUSTER_ID: gTCA24KBTQGmpnFv6eLPzA
      KAFKA_NODE_ID: 2
      KAFKA_JMX_PORT: 9998
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka0:29093,2@kafka1:29093,3@kafka2:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka1:29092,CONTROLLER://kafka1:29093,PLAINTEXT_HOST://0.0.0.0:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9093'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka1 -Dcom.sun.management.jmxremote.rmi.port=9998
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      KAFKA_COMPRESSION_TYPE: producer
    healthcheck:
      test: nc -z localhost 9093 || exit -1
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    volumes:
      - ./volumes/kafka/kafka1:/tmp/kraft-combined-logs
    extends:
      file: common-config.yml
      service: network-deploy-service

  kafka2:
    image: confluentinc/cp-kafka:7.6.1
    restart: on-failure:5
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9095:9095"
      - "9999:9999"
    environment:
      CLUSTER_ID: gTCA24KBTQGmpnFv6eLPzA
      KAFKA_NODE_ID: 3
      KAFKA_JMX_PORT: 9998
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka0:29093,2@kafka1:29093,3@kafka2:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka2:29092,CONTROLLER://kafka2:29093,PLAINTEXT_HOST://0.0.0.0:9095'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka2:29092,PLAINTEXT_HOST://localhost:9095'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka2 -Dcom.sun.management.jmxremote.rmi.port=9999
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      KAFKA_COMPRESSION_TYPE: producer
    healthcheck:
      test: nc -z localhost 9095 || exit -1
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    volumes:
      - ./volumes/kafka/kafka2:/tmp/kraft-combined-logs
    extends:
      file: common-config.yml
      service: network-deploy-service

  schemaregistry0:
    image: confluentinc/cp-schema-registry:7.6.1
    restart: on-failure:5
    hostname: schemaregistry0
    container_name: schemaregistry0
    ports:
      - 8085:8085
    depends_on:
      kafka0:
        condition: service_healthy
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka0:29092,PLAINTEXT://kafka1:29092,PLAINTEXT://kafka2:29092'
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry0
      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry0:8085
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://schemaregistry0:8085 || exit 1" ]
      start_period: 60s
      interval: 20s
      timeout: 120s
      retries: 20
    extends:
      file: common-config.yml
      service: network-deploy-service

  kafka-connect0:
    image: confluentinc/cp-kafka-connect:7.6.1
    restart: on-failure:5
    ports:
      - 8083:8083
    depends_on:
      kafka0:
        condition: service_healthy
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      schemaregistry0:
        condition: service_healthy
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka0:29092,kafka1:29092,kafka2:29092
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: _connect_configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: _connect_offset
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: _connect_status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schemaregistry0:8085
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schemaregistry0:8085
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect0
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8083/ || exit 1" ]
      start_period: 60s
      interval: 20s
      timeout: 120s
      retries: 20
    extends:
      file: common-config.yml
      service: network-deploy-service

#  kafka-init-topics:
#    image: confluentinc/cp-kafka:7.6.1
#    volumes:
#      - ./data/message.json:/data/message.json
#    depends_on:
#      kafka1:
#        condition: service_healthy
#    command: "bash -c 'echo Waiting for Kafka to be ready... && \
#               cub kafka-ready -b kafka1:29092 1 30 && \
#               kafka-topics --create --topic second.users --partitions 3 --replication-factor 1 --if-not-exists --bootstrap-server kafka1:29092 && \
#               kafka-topics --create --topic second.messages --partitions 2 --replication-factor 1 --if-not-exists --bootstrap-server kafka1:29092 && \
#               kafka-topics --create --topic first.messages --partitions 2 --replication-factor 1 --if-not-exists --bootstrap-server kafka0:29092 && \
#               kafka-console-producer --bootstrap-server kafka1:29092 -topic second.users < /data/message.json'"

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    restart: on-failure:5
    ports:
      - 8081:8081
    depends_on:
      kafka0:
        condition: service_healthy
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      schemaregistry0:
        condition: service_healthy
      kafka-connect0:
        condition: service_healthy
    environment:
      SERVER_PORT: 8081
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka0:29092,kafka1:29092,kafka2:29092
      KAFKA_CLUSTERS_0_METRICS_PORT: 9997
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schemaregistry0:8085
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: first
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect0:8083
      DYNAMIC_CONFIG_ENABLED: 'true'
    extends:
      file: common-config.yml
      service: network-deploy-service

#  rabbit:
#    image: rabbitmq:3.13.2-management
#    hostname: messages
#    ports:
#      - "5672:5672"
#      - "15672:15672"
#    healthcheck:
#      test: messages-diagnostics check_port_connectivity
#      interval: 10s
#      timeout: 5s
#      retries: 10
#      start_period: 5s
#    extends:
#      file: common-config.yml
#      service: network-deploy-service

  keycloak:
    image: quay.io/keycloak/keycloak:24.0.4
    container_name: keycloak
    ports:
      - "7080:8080"
    environment:
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD}
      KC_HEALTH_ENABLED: "true"
      KC_METRICS_ENABLED: "true"
      KEYCLOAK_IMPORT: "/tmp/realm-config.json"
    volumes:
      - ../../settings/keycloack/master-microservices-realm-dev.json:/tmp/realm-config.json
    command: "start-dev --import-realm"
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8080 && echo -e 'GET /health/ready HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && cat <&3 | grep -q '200 OK'"]
      interval: 10s
      timeout: 30s
      retries: 10
    extends:
      file: common-config.yml
      service: network-deploy-service

  minio:
    image: minio/minio
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_UPDATE: off
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    extends:
      file: common-config.yml
      service: network-deploy-service

  read:
    image: grafana/loki:3.0.0
    command: "-config.file=/etc/loki/config.yaml -target=read"
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ../../observability/grafana-loki-warehouse/loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    networks: &loki-dns
      kathesamanet:
        aliases:
          - loki

  write:
    image: grafana/loki:3.0.0
    command: "-config.file=/etc/loki/config.yaml -target=write"
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ../../observability/grafana-loki-warehouse/loki-config.yaml:/etc/loki/config.yaml
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    depends_on:
      - minio
    networks:
      <<: *loki-dns

  gateway:
    image: nginx:latest
    depends_on:
      - read
      - write
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1

        events {
          worker_connections   1000;
        }

        http {
          resolver 127.0.0.11;

          server {
            listen             3100;

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }

            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck:
      test: [ "CMD", "service", "nginx", "status" ]
      interval: 10s
      timeout: 5s
      retries: 5
    extends:
      file: common-config.yml
      service: network-deploy-service

  grafana:
    image: grafana/grafana:latest
    environment:
      GF_PATHS_PROVISIONING: /etc/grafana/provisioning
      GF_AUTH_ANONYMOUS_ENABLED: ${GF_AUTH_ANONYMOUS_ENABLED}
      GF_AUTH_ANONYMOUS_ORG_ROLE: ${GF_AUTH_ANONYMOUS_ORG_ROLE}
    depends_on:
      - gateway
    entrypoint:
      - sh
      - -euc
      - |
        /run.sh
    ports:
      - "3000:3000"
    volumes:
      - ../../observability/grafana/datasource.yml:/etc/grafana/provisioning/datasources/datasource.yml
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    extends:
      file: common-config.yml
      service: network-deploy-service

  alloy:
    image: grafana/alloy:v1.0.0
    volumes:
      - ../../observability/alloy-colector/alloy-local-config.yml:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy
    ports:
      - 12345:12345
    depends_on:
      - gateway
    extends:
      file: common-config.yml
      service: network-deploy-service

  accountsdb:
    container_name: accountsdb
    ports:
      - 3306:3306
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE_ACCOUNTS}
    extends:
      file: common-config.yml
      service: microservice-db-config

  loansdb:
    container_name: loansdb
    ports:
      - 3307:3306
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE_LOANS}
    extends:
      file: common-config.yml
      service: microservice-db-config

  cardsdb:
    container_name: cardsdb
    ports:
      - 3308:3306
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE_CARDS}
    extends:
      file: common-config.yml
      service: microservice-db-config

  redis:
    image: redis
    ports:
      - "6379:6379"
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping | grep PONG" ]
      timeout: 10s
      retries: 10
    extends:
      file: common-config.yml
      service: network-deploy-service

  configserver:
    image: "kathesama/configuration-server:v4"
    container_name: configserver-ms
    restart: on-failure:5
    ports:
      - "8888:8888"
      - "7889:5005"
    healthcheck:
      test: "curl --fail --silent localhost:8888/actuator/health/readiness | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    networks:
      - kathesamanet
    extends:
      file: common-config.yml
      service: microservice-base-config

  eurekaserver:
    image: "kathesama/eureka-server:v4"
    container_name: eurekaserver-ms
    restart: on-failure:5
    ports:
      - "8761:8761"
    depends_on:
      configserver:
        condition: service_healthy
    healthcheck:
      test: "curl --fail --silent localhost:8761/actuator/health/readiness | grep UP || exit 1"
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    networks:
      - kathesamanet
    extends:
      file: common-config.yml
      service: microservice-config-server-config

  gatewayserver:
    image: "kathesama/gateway-server:v4"
    container_name: gatewayserver-ms
    restart: on-failure:5
    ports:
      - "8072:8072"
      - "5005:5005"
    depends_on:
      eurekaserver:
        condition: service_healthy
      redis:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      kafka-connect0:
        condition: service_healthy
#      rabbit:
#        condition: service_healthy
    healthcheck:
      test: "curl --fail --silent localhost:8072/actuator/health/readiness | grep UP || exit 1"
      interval: 10s
      timeout: 20s
      retries: 10
      start_period: 30s
    networks:
      - kathesamanet
    environment:
      SPRING_DATA_REDIS_CONNECT-TIMEOUT: ${SPRING_DATA_REDIS_CONNECT_TIMEOUT}
      SPRING_DATA_REDIS_HOST: ${SPRING_DATA_REDIS_HOST}
      SPRING_DATA_REDIS_PORT: ${SPRING_DATA_REDIS_PORT}
      SPRING_DATA_REDIS_TIMEOUT: ${SPRING_DATA_REDIS_TIMEOUT}
      KC_REALM_PORT: ${KC_REALM_PORT}
      KC_REALM_DEFAULT: ${KC_REALM_DEFAULT}
      KC_REALM_SERVER: ${KC_REALM_SERVER}
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  messagebroker:
    image: "kathesama/messages-broker:v4"
    container_name: messages-broker-ms
    restart: on-failure:5
    ports:
      - "7005:5005"
    depends_on:
      gatewayserver:
        condition: service_healthy
#      rabbit:
#        condition: service_healthy
    environment:
      BROKER_SERVICE_HOST: ${BROKER_SERVICE_HOST_ENV}
#      RBMQ_SERVICE_HOST: ${RBMQ_SERVICE_HOST_ENV}
#      RBMQ_SERVICE_PORT: ${RBMQ_SERVICE_PORT_ENV}
#      RBMQ_SERVICE_USERNAME: ${RBMQ_SERVICE_USERNAME_ENV}
#      RBMQ_SERVICE_PASSWORD: ${RBMQ_SERVICE_PASSWORD_ENV}
#      RBMQ_SERVICE_CONNECTION_TIMEOUT: ${RBMQ_SERVICE_CONNECTION_TIMEOUT_ENV}
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  accounts:
    image: "kathesama/account-service:v4"
    container_name: accounts-ms
    restart: on-failure:5
    ports:
      - "8000:8000"
      - "7000:5005"
    depends_on:
      accountsdb:
        condition: service_healthy
      gatewayserver:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 700m
    networks:
      - kathesamanet
    environment:
      SPRING_DATASOURCE_URL: ${SPRING_DATASOURCE_URL_ACCOUNT}
      BROKER_SERVICE_HOST: ${BROKER_SERVICE_HOST_ENV}
#      RBMQ_SERVICE_HOST: ${RBMQ_SERVICE_HOST_ENV}
#      RBMQ_SERVICE_PORT: ${RBMQ_SERVICE_PORT_ENV}
#      RBMQ_SERVICE_USERNAME: ${RBMQ_SERVICE_USERNAME_ENV}
#      RBMQ_SERVICE_PASSWORD: ${RBMQ_SERVICE_PASSWORD_ENV}
#      RBMQ_SERVICE_CONNECTION_TIMEOUT: ${RBMQ_SERVICE_CONNECTION_TIMEOUT_ENV}
    volumes:
      - ../../../account-service/src/main/java:/app/classes
      - ../../../account-service/target/classes:/app/resources
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  cards:
    image: "kathesama/card-service:v4"
    container_name: cards-ms
    restart: on-failure:5
    ports:
      - "8001:8001"
      - "7001:5005"
    depends_on:
      cardsdb:
        condition: service_healthy
      gatewayserver:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 700m
    networks:
      - kathesamanet
    environment:
      SPRING_DATASOURCE_URL: ${SPRING_DATASOURCE_URL_CARD}
    volumes:
      - ../../../card-service/src/main/java:/app/classes
      - ../../../card-service/target/classes:/app/resources
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  loans:
    image: "kathesama/loan-service:v4"
    container_name: loans-ms
    restart: on-failure:5
    ports:
      - "8002:8002"
      - "7002:5005"
    depends_on:
      loansdb:
        condition: service_healthy
      gatewayserver:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 700m
    networks:
      - kathesamanet
    environment:
      SPRING_DATASOURCE_URL: ${SPRING_DATASOURCE_URL_LOAN}
    volumes:
      - ../../../loan-service/src/main/java:/app/classes
      - ../../../loan-service/target/classes:/app/resources
    extends:
      file: common-config.yml
      service: microservice-eureka-config

  prometheus:
    image: prom/prometheus:v2.50.1
    container_name: prometheus
    restart: on-failure:5
    ports:
      - "9090:9090"
    volumes:
      - ../../observability/grafana-prometheus-monitor/prometheus-config.yml:/etc/prometheus/prometheus.yml
    extends:
      file: common-config.yml
      service: network-deploy-service

networks:
  kathesamanet:
    driver: "bridge"